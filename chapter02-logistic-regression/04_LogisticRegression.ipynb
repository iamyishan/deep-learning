{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nn.Module带来了以下好处：\n",
    "\n",
    "模块化构建：对于复杂的网络，你可以将它划分为多个子模块进行构建。然后将它们组合为一个复杂模型。\n",
    "- 自动管理参数：nn.Module会自动追踪模块内所有的参数，无论这些参数是嵌套在子模块中还是作为属性值直接存储在当前模块中。可以通过模块的parameters()或者named_parameters()进行查看。\n",
    "- 统一的forward方法：所有继承自nn.Module的类必须实现一个forward方法，这样各个模块之间根据组合关系对数据进行前向处理。PyTorch里的计算图和自动求梯度机制会帮助我们实现反向传播。\n",
    "- 统一的设备管理：利用nn.Module提供的.to(device)方法，可以方便的将整个模型迁移到GPU或者CPU。\n",
    "- 模型的保存和加载：nn.Module提供了标准的模型保存和加载方法。\n",
    "- 定义了模型的train和eval状态：有的模块在训练时和预测（或者叫推理）时前向传播实现是不同的，可以通过model.train()或者model.eval()统一切换本身，和内部包含的所有模块的状态。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 实现逻辑回归模型\n",
    "要自定义一个模型，需要继承nn.Module，然后你必须实现两个方法，一个是__init__，一个是forward。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegressionModel(nn.Module):\n",
    "    def __init__(self,input_dim) -> None:\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(input_dim,1)  # nn.Linear也继承自nn.Module，输入为input_dim,输出一个值\n",
    "    def forward(self,x):\n",
    "        y_pred = torch.sigmoid(self.linear(x))  # 这里的self.linear(x)是一个张量，torch.sigmoid是一个函数，返回一个张量\n",
    "        return y_pred"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
